# Deep Learning Layers Implementation


## Abstract
This project was created as a python programming part of a deep learning course at the Pattern Recognition Lab of Friedrich-Alexander-Universität Erlangen-Nürnberg (FAU).
Throughout the course, I gained a comprehensive understanding of various aspects related to deep learning, including different layers, optimization techniques,
loss functions, regularization techniques, and time sequential algorithms such as Recurrent Neural Networks (RNN) and Long Short-Term Memory (LSTM).
Additionally, advanced object detection algorithms like Fast R-CNN and segmentation methods were explored, providing a holistic view of deep learning concepts and applications.


## Objective
The objective of the project is to gain a comprehensive understanding of deep learning layers and their functionality by implementing them from scratch. 
This hands-on approach helps us reinforce our understanding of the concepts learned in the deep learning course.


## Implemented Deep Learning Layers
This project includes the following deep learning layers:
- **Dense Layer:** Fully connected layer with customizable activation function.
- **Convolutional Layer:** Convolutional layer with customizable kernel size, padding, and stride.
- **Pooling Layer:** Pooling operations such as max pooling or average pooling.
- **Activation Layer:** Various activation functions such as ReLU, sigmoid, or tanh.
- **Optimization Algorithms:** SGD and ADAM algorithms
- **Loss Functions:** CrossEntropyLoss function.

## Testing
For all implemented layers and functions, unit tests have been written to verify the performance of each component. These tests cover various states and situations to ensure the robustness and correctness of the deep learning functionalities. Prior to using the implemented layers in your projects, it is essential to run these unit tests to validate their behavior.

## Conclusion
Deep learning has often been referred to as a "black box" due to the lack of transparency or interpretability in the internal workings of it. However, through the process of implementing deep learning layers from scratch in this project, we've gained invaluable insights that have illuminated many aspects of how deep learning works.This hands-on approach has allowed us to see beyond the abstraction provided by high-level deep learning frameworks and comprehend the mechanics at play.

